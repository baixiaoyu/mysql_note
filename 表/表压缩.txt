
在创建表的时候，如果使用了row_fromat=compressed的选项，那么这个表会使用比innodb_page_size指定的大小的块。

压缩的块大小是通过key_block_size参数指定的。
无论KEY_BLOCK_SIZE的值如何，压缩级别都是相同的。 在为KEY_BLOCK_SIZE指定较小的值时，您将获得日益小型页面的I / O优势。 但是，如果您指定的值太小，则当数据值无法压缩到足以适应每个页面中的多行时，会有额外的开销来重新组织页面。 根据每个索引的键列长度，对KEY_BLOCK_SIZE的设置是有限制的，如果指定的值太小，那么建表或修改表的语句会失败。
为了获取或更新压缩表中的列值，mysql在buffer pool中同时也保存了未压缩的块，对未压缩表的更新会重新写回到压缩表中，那么针对这种情况，buffer pool的大小需要并没有减小，反而是增大了。

如果在建表的时候没有指定key_block_size，那么默认的就是innodb_page_size的大小。怎么确定该这个值的合适的大小，官方给的方式就是拷贝几个表用不同的值进行测试，看哪个值的效果最好。


对于常规表空间，请记住，删除表不会减小常规表空间.ibd文件的大小，也不会将磁盘空间返回给操作系统

key_block_size这个值像是一个hint,innodb可能使用不同的大小的值。
如果这个值设置的不合理，那么可能会被忽略，并产生一个警告，所以还是需要看下日志是否有警告生成。
32和64位的页大小不支持压缩。

未压缩的页的大小默认是16Kb的，压缩算法不会被key_block_size的大小影响。这个值是决定了每个压缩chunk的大小，影响在每个压缩块中能保存多少行。

设置key_block_size的大小与innodb的页大小，几乎不会有什么压缩效果。
表上的所有的索引也会被使用相同大小的压缩页进行压缩。



监控
select * from information_schema.INNODB_CMP;
查看下面的表需要开启innodb_cmp_per_index_enabled这个选项
select * from information_schema.INNODB_CMP_PER_INDEX ;

怎么去判断这个表是否适合压缩
查看上面的表监控，然后看是否有很高的压缩成功率，如果有，那么就说明这个表是适合压缩的。
如果有很高的压缩失败的比例，那么可以调整innodb_compression_level, innodb_compression_failure_threshold_pct, and innodb_compression_pad_pct_max 这几个选项。

mysql使用的是zlib库，LZ77压缩算法。你可以通过innodb_compression_level 来调整压缩级别和cpu使用间的平衡。



在测试的过程中，使用了带外键约束的表，通过create table like方式创建表，虽然这种方式创建的表没有将约束拷贝过来，但是设置后，插入数据在5.6版本的情况下依然是没有进行压缩，在5.7上是能正常压缩的。并且在create table like方式创建表后，手工添加了约束，5.6版本上依然是没有压缩，5.7版本还是正常的进行了压缩。在5.7上压缩后，压缩的效果有50%



mysql的压缩功能跟oracle中的是一样的，也是建议在大数据量的读多的情况，并且是有很多字符的情况下使用。但是要评估buffer的使用。压缩的主要是重复的数据，要是表中的数据都是随机的，那么压缩的效果就不怎么好。另外就是系统是耗io的，而不是耗cpu的，这种情况下比较适合压缩。


评估压缩的方式就是找个文件系统的工具，比如gzip，先在文件级别上压缩下，mysql的压缩效果会稍微不如文件的压缩效果。


压缩页大小的设置选择，如果这个页的设置太大，会浪费一些空间，但是设置过小问题更多，对插入，更新都有影响，还有就是节点的分裂。



压缩的方式，对于页的压缩，要频繁的修改，所以mysql有些优化的手段：
1 记录元数据在node节点上，对于删除，删除标记来说不需要任何的压缩操作。
2 会有一个页的修改记录log，所有的变更操作先记录到这个页上，然后log用完后，批量的变更到页中，优化了解压的次数。如果重新压缩失败了，那么mysql会分裂，重复这个过程，直到插入，更新成功。
3在压缩的页中会保留一些空白空间，避免上面出现的频繁的分裂操作。通过参数： innodb_compression_failure_threshold_pct, and innodb_compression_pad_pct_max可以调整这个机制。



压缩页与buffer pool
压缩页在buffer pool中也有个非压缩的页存在，在buffer pool不够的时候会驱逐非压缩页来腾空间，然后在驱逐压缩页。

mysql内部有自适应的算法用lru来管理压缩页和非压缩页，能够根据系统的类型，是耗io还是耗cpu去自动的调整优化。具体实现没有讲。

压缩与redo log的关系，可以看到不能轻易的修改系统的库，对数据库还是有影响的。
在将压缩页面写入数据文件之前，MySQL会将页面的副本写入重做日志（如果从上次写入数据库开始已重新压缩）。 这样做是为了确保重做日志可用于崩溃恢复，即使在不太可能的情况下，zlib库也会升级，并且这种更改会引起压缩数据的兼容性问题。 因此，使用压缩时，可以预期日志文件的大小会增加，或者需要更频繁的检查点。 日志文件大小或检查点频率的增加量取决于压缩页面以需要重新组织和再压缩的方式修改的次数。

innodb_log_compressed_pages这个参数控制着是否将压缩页写入redo log,如果你确保zlib的版本一直不变，可以关闭这个写入，降低redo log的使用。


innodb_compression_pad_pct_max这个参数控制着压缩页中的空闲空间的大小，来避免分页的产生。

innodb_compression_level 这个参数控制着压缩的级别
innodb_compression_failure_threshold_pct指定更新压缩表时压缩失败的截止点。 当这个阈值通过时，MySQL开始在每个新的压缩页面中留下额外的空闲空间，动态调整空闲空间量直到由innodb_compression_pad_pct_max指定的页面大小的百分比


对大表进行压缩的几个方案：
https://www.percona.com/blog/2013/02/11/adventures-in-archiving/

